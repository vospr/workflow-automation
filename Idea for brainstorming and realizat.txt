Idea for brainstorming and realization. 

As AI engineer of EPAM I receive a client project it could be a greenfield or brownfield project. My task could be to create a demo of a new product or integrate a new feature for existing complex project, for example make AI integration to workflow for summarization/ categorization/ estimation and other type of work where AI agent can support users. 

Technical stack. 
On the client side - Confluence contains historical information, and Jira has a standard structure (epic, story, task, subtask). I don't have admin rights to Jira, I'm a standard user. 
The Client could already has an API subscription to LLM or it could be a Copilot with a full Azure stack or not we don't know. For this project I use my own tech stack: 
- I have personal Claude Code Pro/ OpenAI Codex Pro, Cursor with 20USD subscription and standard VS Code. 
- For test I have my personal Jira, confluence and for AI teammate I have email ai.vospr@gmail.com 
- In the latest time for personal projects I use Claude Code & OpenAI Codex in terminal VS Code, not even CLI or extensions, for me it's comfortable to have a folder where I'm working with files and terminal at the same place. 
- My project folder is on local machine and I will create a GitHub repository (it's not done yet). 
- To work on client's project i can use a new git repository or a new git branch for existing client's repository I don't know yet. 

I understand principles of spec-driven development and context engineering. SDD is out of scope for current brainstorming but as example read @C:\Users\AndreyPopov\Documents\EPAM\Claude_Template. I want to use BMAD method and agents/ workflow and possibly will install it every time from original repository and the same for DMTOOLS @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\DMTOOLS_BMAD_prerequisites.txt, as their team is continuously working on their development. I understand that some tools can be installed and used directly but some needs modification depends based on my credentials @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\dmtools.txt, the most possible scenario when I for each client will create the separate SDD and agents, but keep the context engineering principles, as example CLAUDE.md in @C:\Users\AndreyPopov\Documents\EPAM\Claude_Template

How I can see the front-end workflow of this project:
Client assign to me a task in Jira. I collect the context of the task - it's an epic, story, previous tasks and so on. It could contain not only description but also attached .pdf or .docx files, mermaid diagrams, external web links. Based on analysis of this information I can ask some questions in comments or start to work on the task. I can split task on subtasks and create subtasks and work on them in sequence or in parallel. I can change the status of task/ subtasks assigned to me in progress/ done and others. Also, I can create a story/ a description in Confluence for this new feature. 

How it can be done in the back-end workflow of this project. 
Tasks assign to me triggers Jira automation and initiate a Git action workflow. It calls the LLM. Main agent identify the task, it can keep me in the loop or call for subagents to execute the work (estimation, code writing, documentation preparation and so on). After work will be done it sends result back to Jira in the form of a comment, questions, subtask creation or task status change. 

I can work alone or add the AI teammate to Jira and in this case AI teammate communicate with me in Jira 'on-behalf' of LLM via comments that looks like I have 'CLI' in Jira and do not work in terminal of vs code: LLM agent asked me questions not in terminal of VS Code (for example @....) but in Jira: questions -> I answer -> LLM continue to work based on my answers. Still in the background I have a local folder with SDD rules/ agents/ CLAUD.md file/ planning and implementation artifacts and so on. This folder initiated at Git and all the back end process aligns to Context engineering

The example of this kind of execution you can read in transcript @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\Case_1.txt

To collect information from ticket assigned to me (incl. epic, story description and information from files attached to jira tickets) I want to use not LLM but code to perform all preparation tasks. Example of it you can find at DMTOOLS repository @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\istin-dmtools.txt and preliminary integration in file @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\DMTOOLS_BMAD_Integration_Scenarios.md, 
Paths to repositories: @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\DMTOOLS_BMAD_Integration_Scenarios.txt
I don't know what tool is better for connection to Jira - use open source mcp as it was defined in rules specified in @C:\Users\AndreyPopov\Documents\EPAM\Claude_Template
or MCP and rules developed in DMTOOLS. 


How i'd like to make this project. 
1. i want to understand the possible architecture of these 2 Jira scenarios specified above, know how to use gitaction, and quickly switch between mine and client's llm. 
2. I'm not comfortable with functionality of connection to Jira and how pre-processing/ preparation JQL works for Jira history extraction. I'd like to make it in priority even with a simple request of information from Jira and post a comment to Jira (e.g. AI teammate asks questions when BA works in LLM). 
In my Jira I have a test 'AI Teammate Learning' space where i created previously tasks (ATL-1 .. ATL-31), ATL-2 has subtasks. As assignee I also have AI Teammate bot. Also I have 1 global automation rule 'AI Teammate â€“ Generate Learning Questions' @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\automation-rule.json that works with gitaction workflow @C:\Users\AndreyPopov\Documents\EPAM\Workflow_automation\ai-teammate.yml
3. More or less i'm fine with SDD and context engineering. Therefore I would de-prioritize it. 
4. I would start from the scenario without AI teammate first and after add it as extended functionality. 